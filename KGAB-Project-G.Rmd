---
title: "KGAB Project G"
author: "Kemardo Tyrell, Giovanna Morara, Benjamin Leslie, and Alex Arhin"
date: "March 14, 2023"
output:
  html_document:
    df_print: paged
---

*This project will require you to collaborate with some of your fellow students to complete a statistical analysis and report. Here are some of the tasks that you must accomplish.*

- Create a public GitHub repository with an RStudio project file (team leader)
- Put a description of the project in the README.md file (team leader)
- Email team members and Mike the repository address (team leader)
- Write a short introduction
- Provide a graphical display and descriptive statistics to compare groups
- Conduct an analysis of variance (ANOVA) for omnibus inference
- Check the conditions necessary for valid ANOVA inference
- Conduct a bootstrap for omnibus inference without needing conditions
- Construct Tukey pairwise confidence intervals (if appropriate)
- Write a conclusions section
- Assemble a complete knittable report (team leader)

*If you write any functions, put these in a **Functions** folder. Put data in a **Data** folder. These should be subfolders in your main project folder. Your finished notebook should be neat and organized. Save this notebook with your team name and **Project G** in the file name, rather than the report title. Leave the instructions in place and begin your report after the last horizontal line below. All team members will receive the same score for this project. (40 points possible)*

***

The *HSB2 Data* includes variables collected on a random sample of high school seniors. Conduct an analysis to compare performance on the test variable assigned to your team for the three socioeconomic groups. Include a graphical display and descriptive statistics. Also include an omnibus analysis that assumes valid conditions for parametric inference (ANOVA) as well as an omnibus analysis that does not assume these conditions (bootstrap). Construct pairwise Tukey confidence intervals, if appropriate.

***
```{r include=FALSE}
# Clear the environment
rm(list = ls())

# Load the libraries
library(here)
library(dplyr)

# Load data
data <- read.csv(here("Data", "hsb2.csv"))
the_data <- read.csv(here("Data", "hsb2.csv"))
```


## Introduction

The HSB2 data set contains test scores for 200 high school students in subject tests for reading, writing, mathematics, science, and social studies. This data set also provides the socioeconomic status (SES) level for each student. This study will divide the students into the three SES levels to determine if differences in the science scores exist between SES levels. 

```{r echo=FALSE}
# ses ordinal  (1=low 2=middle 3=high)  
data$ses <- factor(data$ses,
                   labels = c("Low",
                              "Middle",
                              "High"))

# Obtain boxplots.

boxplot(data$science ~ data$ses,
        ylim = c(0, 100),
        xlab = "Socioeconomic Status",
        ylab = "Science Scores",
        main = "Figure 1. Scores depending on SES")

```

Figure 1. Shows a boxplot of the score distributions on the science HSB2 test divided by socioeconomic status. This figure shows us that the high SES level has the highest mean and contains an outlier score on the lower end.

#### Table 1. Five Number Summary of Science Scores by SES Level
```{r echo=FALSE}
ses_summary <- tapply(data$science, data$ses, summary)
ses_summary
ses_sd <- tapply(data$science, data$ses, sd)
ses_sd
```

Table 1 shows the five number summary of science scores for each SES level. The high SES level was found to have the highest mean score at `r round(ses_summary$High[4],2)`. Middle SES had the highest maximum value at `r round(ses_summary$Middle[6],2)`. Middle SES also had the highest minimum value at `r round(ses_summary$Middle[1],2)` while the low SES level had the lowest minimum value at `r round(ses_summary$Low[1],2)`.


***

## Analysis of Variance

#### Check the conditions necessary for valid ANOVA inference

###### Groups are independent (research design)

This study is observational so individuals are classified to one SES.

###### Units within groups are independent to each other (research design)

The students are randomly selected. It could still be possible that near
relatives are from one family (therefore non independent).

###### Now let's check the conditions for inference (statistic)


```{r echo=FALSE}
model <- lm(data$science ~ data$ses)
std_residual <- rstandard(model)
qqnorm(std_residual, main = "Figure 2. Normal Q-Q Plot")
qqline(std_residual)
```

The sampling distribution is normally distributed, although there is a deviation for higher levels. This can be seen in Figure 2. However, for each group we have more than 30 participants and the deviations is not harsh. Therefore, the condition is met.

#### Table 2. Number of Cases by SES Level
```{r echo=FALSE}
table(data$ses)
```

###### Residual withint groups have the same variation

Looking at the variance of residuals within the categories. 

```{r echo=FALSE}
plot(model$fitted.values, model$residuals,
     xlab = "Fitted Values",
     ylab = "Residuals",
     main = "Figure 3. Plot of Residuals vs. Fit")

abline(0,0)
```

There is some skewness in the in the High SES. But the spread around the 
means homogeneous for the most cases.

###### Sampling distribution of means are normal distributions

We do not have a skewed distribution, we also have more than 30
participant for each group so for the Central Limit Theorem, so we have
a normal sampling distribution. 

---------------------------------------------------------------------------

#### Conduct an analysis of variance (ANOVA) for omnibus inference

We will use function aov to get the analysis of variance

#### Figure 4. Analysis of Variance Summary
```{r echo=FALSE}
aov.model <- aov(data$science ~ data$ses)
aov.model
summary(aov.model)
```
Choosing a 95% certanty level, we can reject the null hypothesis: there is
some difference between one or more of the groups.

#### Analysis of pairs of mean.

This section is to construct confidence intervals for each pair of 
conditions to understand the differences between the groups.

```{r include=FALSE}
## Checking dummies variables
# model <- lm(data$science ~ data$ses)
# summary(model)
# anova(model)
```


***

## Inference and Confidence Interval
```{r include=FALSE}
 # Initialize objects
 mean_vector <- NULL
 n <- length(the_data$science)
```

```{r echo=FALSE}
# Loop

sesLow <- data[which(data$ses == "Low"),] 
sesMiddle <- data[which(data$ses == "Middle"),]
sesHigh <-  data[which(data$ses == "High"),]
nLow <- length(sesLow)
nMiddle <- length(sesMiddle)
nHigh <- length(sesHigh)
Diff <- NULL

# mean_Vector_Low <- NULL
# mean_Vector_Middle <- NULL 
# mean_Vector_High <- NULL

 for (i in 1:10000) {
   sampleLow <- sample(sesLow$science, nLow, replace = TRUE)
   mean_Vector_Low <- mean(sampleLow)
   sampleMiddle <- sample(sesMiddle$science, nLow, replace = TRUE)
   mean_Vector_Middle <- mean(sampleMiddle)
   sampleHigh <- sample(sesHigh$science, nLow, replace = TRUE)
   mean_Vector_High <- mean(sampleHigh)
   
   Lower <- min(mean_Vector_Low,mean_Vector_Middle,mean_Vector_High)
   Higher <- max(mean_Vector_Low,mean_Vector_Middle,mean_Vector_High)
   Diff <- c(Diff, (Higher-Lower))
 }

# Sampling Distribution

Diff <- sort(Diff)
Boot_int <- c(Diff[251], Diff[9750])

```

The code above uses bootstrapping to construct a sampling distribution of the mean of the "science" column in the data frame or list "the_data". The code generates 10,000 bootstrap samples of size "n" with replacement from the "science" column and computes the mean of each sample. The resulting means are stored in the "mean_vector" variable, which contains the distribution of the means of the bootstrap samples. The "mean_vector" is then sorted in ascending order and the lower and upper bounds of the 95% bootstrap confidence interval are extracted using the quantile() function. This way, the bounds are not dependent on the number of bootstrap samples generated. The resulting confidence interval was found to be `r round(Boot_int[1],2)` < $mu$ < `r round(Boot_int[2],2)`

### Tukey 

When there is homogeneity of variance among all conditions.
It gives the narrowest confidence interval.

```{r include=FALSE}
aov.model <- aov(data$science ~ data$ses)
Tukey_results <- TukeyHSD(aov.model)
```

We can also obtain a plot to illustrate these differences, if we'd like.

#### Figure 5. Family-Wise Confidence Level by SES Levels
```{r echo=FALSE}
plot(Tukey_results)
```
***

## Conclusions
An analysis of variance was conducted to compare HSB2 science performances for three socioeconomic groups. The data set was found to satisfy the criteria for conducting a valid ANOVA as the groups were independent, the units within groups were independent, the data is normally distributed, and the distribution is not skewed. Using the ANOVA, we can say with a 95% level of confidence that there is not a statistically significant difference between two or more of the groups.

Using bootstrapping, a 95% confidence interval for the true population mean science score was found to be `r round(Boot_int[1],2)` < $mu$ < `r round(Boot_int[2],2)`. A Tukey pairwise estimate was conducted and found that only the high-low relationship yielded a statistically significant p value, p > 0.05. This relationship was also the only one to yield a confidence interval that did not contain zero. This supports that the high-low SES mean score difference does not equal zero with 95 percent confidence.

In total, these findings suggest that there is mixed evidence to support a difference in science scores between socioeconomic status levels. It is worth noting that the relationship between low SES and high SES students' scores yielded the most consistent evidence to support a difference in the mean score of the two groups.

